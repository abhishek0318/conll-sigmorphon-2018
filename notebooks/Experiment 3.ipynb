{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointer Generator over characters and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_CHAR = '⏵'\n",
    "STOP_CHAR = '⏹'\n",
    "UNKNOWN_CHAR = '⊗'\n",
    "UNKNOWN_TAG = '⊤'\n",
    "PAD_CHAR = '₮'\n",
    "PAD_TAG = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from itertools import zip_longest\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    \"\"\"Loads data.\n",
    "\n",
    "    Args:\n",
    "        file_name: path to file containing the data\n",
    "\n",
    "    Returns:\n",
    "        lemmas: list of lemma\n",
    "        tags: list of tags\n",
    "        inflected_forms: list of inflected form\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_name, 'r', encoding='utf') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    lemmas = []\n",
    "    tags = []\n",
    "    inflected_forms = []\n",
    "\n",
    "    for line in text.split('\\n')[:-1]:\n",
    "        lemma, inflected_form, tag = line.split('\\t')\n",
    "        lemmas.append(lemma)\n",
    "        inflected_forms.append(inflected_form)\n",
    "        tags.append(tag) \n",
    "\n",
    "    return lemmas, tags, inflected_forms\n",
    "\n",
    "def get_index_dictionaries(lemmas, tags, inflected_forms):\n",
    "    \"\"\"Returns char2index, index2char, tag2index\n",
    "\n",
    "    Args:\n",
    "        lemmas: list of lemma\n",
    "        tags: list of tags\n",
    "        inflected_forms: list of inflected form\n",
    "\n",
    "    Returns: \n",
    "        char2index: a dictionary which maps character to index\n",
    "        index2char: a dictionary which maps index to character\n",
    "        tag2index: a ditionary which maps morphological tag to index \n",
    "    \"\"\"\n",
    "\n",
    "    unique_chars = set(''.join(lemmas) + ''.join(inflected_forms))\n",
    "    unique_chars.update(START_CHAR, STOP_CHAR) # special start and end symbols\n",
    "    unique_chars.update(UNKNOWN_CHAR) # special charcter for unknown word\n",
    "    char2index = {}\n",
    "    index2char = {}\n",
    "\n",
    "    char2index[PAD_CHAR] = 0\n",
    "    index2char[0] = PAD_CHAR\n",
    "    \n",
    "    for index, char in enumerate(unique_chars):\n",
    "        char2index[char] = index + 1\n",
    "        index2char[index + 1] = char\n",
    "\n",
    "    unique_tags = set(';'.join(tags).split(';'))\n",
    "    unique_tags.update(UNKNOWN_TAG)\n",
    "    tag2index = {tag:index+1 for index, tag in enumerate(unique_tags)}\n",
    "    tag2index[PAD_TAG] = 0\n",
    "\n",
    "    return char2index, index2char, tag2index\n",
    "\n",
    "def get_combined_index_dictionaries(lemmas, tags, inflected_forms):\n",
    "    \"\"\"Returns char2index, index2char\n",
    "\n",
    "    Args:\n",
    "        lemmas: list of lemma\n",
    "        tags: list of tags\n",
    "        inflected_forms: list of inflected form\n",
    "\n",
    "    Returns: \n",
    "        char2index: a dictionary which maps inputs and  to index\n",
    "        index2char: a dictionary which maps index to inputs\n",
    "    \"\"\"\n",
    "\n",
    "    unique_chars = set(''.join(lemmas) + ''.join(inflected_forms))\n",
    "    unique_chars.update(START_CHAR, STOP_CHAR, UNKNOWN_CHAR) # special start and end symbols  \n",
    "    \n",
    "    input2index = {}\n",
    "    index2input = {}\n",
    "    \n",
    "    input2index[PAD_CHAR] = 0\n",
    "    index2input[0] = PAD_CHAR\n",
    "        \n",
    "    for index, char in enumerate(unique_chars, start=1):\n",
    "        input2index[char] = index\n",
    "        index2input[index] = char\n",
    "        \n",
    "    char_vocab_length = len(input2index.keys())\n",
    "\n",
    "    unique_tags = set(';'.join(tags).split(';'))\n",
    "    unique_tags.add(UNKNOWN_TAG) # special character for unknown tags\n",
    "    \n",
    "    for index, char in enumerate(unique_tags, start=char_vocab_length):\n",
    "        input2index[char] = index\n",
    "        index2input[index] = char\n",
    "\n",
    "    return input2index, index2input, char_vocab_length\n",
    "\n",
    "def words_to_indices(words, char2index, tensor=False, start_char=False, stop_char=False):\n",
    "    \"\"\"Converts list of words to a list with list containing indices\n",
    "\n",
    "    Args:\n",
    "        words: list of words\n",
    "        char2index: dictionary which maps character to index\n",
    "        tensor: if to return a list of tensor  \n",
    "\n",
    "    Returns:\n",
    "        tensor: list of list/tensor containing indices for a sequence of characters\n",
    "    \"\"\"\n",
    "\n",
    "    list_indices = []\n",
    "    for word in words:\n",
    "        word_indices = []\n",
    "        if start_char:\n",
    "            word_indices.append(char2index[START_CHAR])\n",
    "        for char in word:\n",
    "            if char in char2index.keys():\n",
    "                word_indices.append(char2index[char])\n",
    "            else:\n",
    "                word_indices.append(char2index[UNKNOWN_CHAR])\n",
    "        if stop_char:\n",
    "            word_indices.append(char2index[STOP_CHAR])\n",
    "        if tensor:\n",
    "            word_indices = torch.Tensor(word_indices)\n",
    "        list_indices.append(word_indices)\n",
    "\n",
    "    return list_indices\n",
    "\n",
    "def tag_to_vector(tags, tag2index):\n",
    "    \"\"\"Returns one hot representation of tags given a tag.\n",
    "\n",
    "    Args:\n",
    "        tags: list of string representation of tag (eg, V;IND;PRS;2;PL)\n",
    "\n",
    "    Returns:\n",
    "        tag_vectors: list of 1D tensors with one hot representation of tags \n",
    "    \"\"\"\n",
    "\n",
    "    tag_vectors = []\n",
    "    for tag in tags:\n",
    "        tag_vector = torch.zeros(len(tag2index))\n",
    "        for tag_feature in tag.split(';'):\n",
    "            if tag_feature in tag2index:\n",
    "                tag_vector[tag2index[tag_feature]] = 1\n",
    "            else:\n",
    "                tag_vector[tag2index[UNKNOWN_TAG]] = 1\n",
    "        tag_vectors.append(tag_vector)\n",
    "    return tag_vectors\n",
    "\n",
    "def tag_to_indices(tags, tag2index):\n",
    "    \"\"\"Converts list of tags to a list of lists containing indices\n",
    "\n",
    "    Args:\n",
    "        words: list of tags\n",
    "\n",
    "    Returns:\n",
    "        tensor: list of list containing indices of sub_tags\n",
    "    \"\"\"\n",
    "    \n",
    "    list_indices = []\n",
    "    for tag in tags:\n",
    "        tag_indices = []\n",
    "        for sub_tag in tag.split(';'):\n",
    "            if sub_tag in tag2index.keys():\n",
    "                tag_indices.append(tag2index[sub_tag])\n",
    "            else:\n",
    "                tag_indices.append(tag2index[UNKNOWN_TAG])\n",
    "        list_indices.append(tag_indices)\n",
    "\n",
    "    return list_indices\n",
    "    \n",
    "\n",
    "def indices_to_word(indices, index2char):\n",
    "    \"\"\"Returns a word given list contaning indices of words\n",
    "\n",
    "    Args:\n",
    "        indices: list containing indices\n",
    "\n",
    "    Returns:\n",
    "        word: a string\n",
    "    \"\"\"\n",
    "\n",
    "    return ''.join([index2char[index] for index in indices])[:-1]\n",
    "\n",
    "def pad_lists(lists, pad_int, pad_len=None):\n",
    "    \"\"\"Pads lists in a list to make them of equal size\"\"\"\n",
    "    \n",
    "    if pad_len is None:\n",
    "        pad_len = max([len(lst) for lst in lists])\n",
    "    new_list = []\n",
    "    for lst in lists:\n",
    "        if len(lst) < pad_len:\n",
    "            new_list.append(torch.tensor(lst + [pad_int] * (pad_len-len(lst))))\n",
    "        else:\n",
    "            new_list.append(torch.tensor(lst[:pad_len]))\n",
    "    return torch.stack(new_list)\n",
    "\n",
    "def merge_lists(lists1, lists2):\n",
    "    \"\"\"Add two list of lists.\"\"\"\n",
    "    \n",
    "    merged_lists = []\n",
    "    for list1, list2 in zip(lists1, lists2):\n",
    "        merged_lists.append(list1 + list2)\n",
    "    return merged_lists\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    correct_count = 0\n",
    "    for prediction, target in zip(predictions, targets):\n",
    "        if prediction == target:\n",
    "            correct_count += 1\n",
    "    return correct_count / len(predictions)\n",
    "\n",
    "def average_distance(predictions, targets):\n",
    "    total_distance = 0\n",
    "    for prediction, target in zip(predictions, targets):\n",
    "        total_distance += Levenshtein.distance(prediction, target)\n",
    "    return total_distance / len(predictions)\n",
    "\n",
    "def evaluate(predictions, targets):\n",
    "    return accuracy(predictions, targets), average_distance(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'middle-french'\n",
    "dataset = 'high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas, tags, inflected_forms = load_data('./conll2018/task1/all/{}-train-{}'.format(language, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_train, lemmas_val, tags_train, tags_val, inflected_forms_train, inflected_forms_val = train_test_split(lemmas, tags, inflected_forms, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input2index, index2input, char_vocab_size = get_combined_index_dictionaries(lemmas_train, tags_train, inflected_forms_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedding_size = 300\n",
    "hidden_size = 100\n",
    "input_vocab_size = len(index2input.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    class Attention(nn.Module):\n",
    "        def __init__(self, hidden_size):\n",
    "            # Custom\n",
    "\n",
    "            super(Attention, self).__init__()\n",
    "            self.linear = nn.Linear(3*hidden_size, 1)\n",
    "\n",
    "        def forward(self, encoded_input, hidden_state, input_mask):\n",
    "            src_len = encoded_input.shape[1]\n",
    "            concat = torch.cat([encoded_input, hidden_state.transpose(0, 1).expand(-1, src_len, -1)], dim=2)\n",
    "            attn_weights = F.tanh(self.linear(concat).squeeze())\n",
    "\n",
    "            input_mask = input_mask.float()\n",
    "            input_mask = torch.where(input_mask == 0, torch.zeros_like(input_mask), torch.ones_like(input_mask) * float('inf'))\n",
    "            attn_weights = attn_weights - input_mask\n",
    "            # attn_weights.data.masked_fill_(input_mask, float('-inf'))\n",
    "\n",
    "            attn_weights = F.softmax(attn_weights, dim=1)\n",
    "            return attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    class Attention(nn.Module):\n",
    "        def __init__(self, hidden_size, intermediate_size=100):\n",
    "            # concat scoring function - global attention \n",
    "            # https://arxiv.org/pdf/1508.04025.pdf\n",
    "\n",
    "            super(Attention, self).__init__()\n",
    "            if intermediate_size is None:\n",
    "                intermediate_size = int(attention_input_size ** (1/2))\n",
    "            self.W_a = nn.Linear(3*hidden_size, intermediate_size, bias=False)\n",
    "            self.v_a = nn.Linear(intermediate_size, 1, bias=False)\n",
    "\n",
    "        def forward(self, encoded_input, hidden_state, input_mask):\n",
    "            src_len = encoded_input.shape[1]\n",
    "            concat = torch.cat([encoded_input, hidden_state.transpose(0, 1).expand(-1, src_len, -1)], dim=2)\n",
    "            attn_weights = F.tanh(self.W_a(concat))\n",
    "            attn_weights = self.v_a(attn_weights).squeeze()\n",
    "            attn_weights.data.masked_fill_(input_mask, float('-inf'))\n",
    "            attn_weights = F.softmax(attn_weights, dim=1)\n",
    "            return attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, p=0.3):\n",
    "        # general scoring function - global attention \n",
    "        # https://arxiv.org/pdf/1508.04025.pdf\n",
    "\n",
    "        super(Attention, self).__init__()\n",
    "        self.W_a = nn.Linear(2*hidden_size, hidden_size, bias=False)\n",
    "        # self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, encoded_input, hidden_state, input_mask):\n",
    "        src_len = encoded_input.shape[1]\n",
    "        attn_weights = torch.bmm(self.W_a(encoded_input), hidden_state.transpose(0, 1).transpose(1, 2)).squeeze()\n",
    "        attn_weights.data.masked_fill_(input_mask, float('-inf'))\n",
    "        # attn_weights = dropout(attn_weights)\n",
    "        attn_weights = F.softmax(attn_weights, dim=1)\n",
    "        return attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    class Attention(nn.Module):\n",
    "        def __init__(self, attention_input_size, intermediate_size=100):\n",
    "            super(Attention, self).__init__()\n",
    "\n",
    "        def forward(self, encoded_input, hidden_state, input_mask):\n",
    "            src_len = encoded_input.shape[1]\n",
    "            attn_weights = (encoded_input * torch.cat([hidden_state.transpose(0, 1).expand(-1, src_len, -1), hidden_state.transpose(0, 1).expand(-1, src_len, -1)], dim=2)).sum(dim=2)\n",
    "\n",
    "            input_mask = input_mask.float()\n",
    "            input_mask = torch.where(input_mask == 0, torch.zeros_like(input_mask), torch.ones_like(input_mask) * float('inf'))\n",
    "            attn_weights = attn_weights - input_mask\n",
    "            #attn_weights.masked_fill_(input_mask, float('-inf'))\n",
    "\n",
    "            attn_weights = F.softmax(attn_weights, dim=1)\n",
    "            return attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerationProbability(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size):\n",
    "        super(GenerationProbability, self).__init__()\n",
    "        self.linear_context = nn.Linear(2*hidden_size, 1)\n",
    "        self.linear_hidden = nn.Linear(hidden_size, 1)\n",
    "        self.linear_input = nn.Linear(embedding_size, 1)\n",
    "        \n",
    "    def forward(self, context, hidden_state, decoder_input):\n",
    "        return F.sigmoid(self.linear_context(context) + self.linear_hidden(hidden_state.squeeze()) + self.linear_input(decoder_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedder = nn.Embedding(input_vocab_size, embedding_size, padding_idx=input2index[PAD_CHAR]).to(device)\n",
    "Encoder = nn.LSTM(embedding_size, hidden_size, batch_first=True, bidirectional=True).to(device)\n",
    "attention = Attention(hidden_size).to(device)\n",
    "Decoder = nn.LSTM(embedding_size + 2 * hidden_size, hidden_size, batch_first=True).to(device)\n",
    "linear_vocab = nn.Linear(3 * hidden_size, char_vocab_size - 1).to(device) # remove pad character option\n",
    "generation_prob = GenerationProbability(embedding_size, hidden_size).to(device)\n",
    "log_softmax = nn.LogSoftmax(dim=2).to(device)\n",
    "criterion = nn.NLLLoss(ignore_index=-1)\n",
    "params = list(Embedder.parameters()) + list(Encoder.parameters()) + list(Decoder.parameters()) + \\\n",
    "        list(linear_vocab.parameters())+ list(attention.parameters()) + list(generation_prob.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(lemmas_val, tags_val, inflected_forms_val, batch_size=32, attn_debug=False, max_pred_len=25):\n",
    "    max_pred_len = 25\n",
    "\n",
    "    inflected_predicted = []\n",
    "    inflected_forms_true = []\n",
    "    if attn_debug:\n",
    "        input_seq = []\n",
    "        attn_weights_all = []\n",
    "        p_gen_all = []\n",
    "    output_indices = []\n",
    "\n",
    "    for batch in grouper(zip(lemmas_val, tags_val, inflected_forms_val), batch_size):\n",
    "        batch = list(filter(lambda x: x is not None, batch))\n",
    "        lemmas, tags, inflected_forms = zip(*batch)\n",
    "\n",
    "        lemmas_indices = words_to_indices(lemmas, input2index, start_char=True, stop_char=True)\n",
    "        tags_indices = tag_to_indices(tags, input2index)    \n",
    "        input_indices = merge_lists(lemmas_indices, tags_indices)\n",
    "\n",
    "        # Sort by length of input sequence\n",
    "        input_indices, inflected_forms = zip(*sorted(zip(input_indices, inflected_forms), key=lambda x: len(x[0]), reverse=True))        \n",
    "        if attn_debug:\n",
    "            input_seq += [[index2input[index] for index in input_indices1] for input_indices1 in input_indices]\n",
    "        input_indices = [torch.tensor(lst) for lst in input_indices]\n",
    "\n",
    "        input_tensor = pad_sequence(input_indices, padding_value=input2index[PAD_CHAR], batch_first=True).to(device)\n",
    "        embedding = Embedder(input_tensor)\n",
    "        lengths = [Tensor.shape[0] for Tensor in input_indices]\n",
    "        packed_input = pack_padded_sequence(embedding, lengths, batch_first=True)\n",
    "        encoded_packed_seq, (hidden, cell) = Encoder(packed_input)\n",
    "        encoded_input = pad_packed_sequence(encoded_packed_seq, batch_first=True)[0]\n",
    "\n",
    "        input_mask = input_tensor == 0\n",
    "        # input_mask = torch.where(input_mask > 0, torch.zeros_like(input_mask), torch.ones_like(input_mask) * float('inf')) \n",
    "\n",
    "\n",
    "        # Decode\n",
    "        hidden_state = hidden[0,:,:] + hidden[1,:,:]\n",
    "        hidden_state = hidden_state.unsqueeze(0)\n",
    "        cell_state = torch.zeros(1, len(lengths), hidden_size).to(device)\n",
    "\n",
    "        decoder_input = torch.tensor([input2index[START_CHAR]] * len(lengths)).to(device)\n",
    "        decoder_input = Embedder(decoder_input)\n",
    "\n",
    "\n",
    "        outputs = []\n",
    "        attn_weights_sequence = []\n",
    "        p_gen_seq = []\n",
    "        for seq in range(0, max_pred_len):\n",
    "            attn_weights = attention(encoded_input, hidden_state, input_mask)\n",
    "            context = torch.bmm(attn_weights.unsqueeze(1), encoded_input).squeeze()\n",
    "\n",
    "            decoder_input_concat = torch.cat([context, decoder_input], dim=1)\n",
    "\n",
    "            output, (hidden_state, cell_state) = Decoder(decoder_input_concat.unsqueeze(1), (hidden_state, cell_state))\n",
    "            p_vocab = F.relu(linear_vocab(torch.cat([hidden_state, context.unsqueeze(0)], dim=2)))    \n",
    "            p_vocab = F.softmax(p_vocab.squeeze(), dim=1)\n",
    "            p_gen = generation_prob(context, hidden_state, decoder_input)\n",
    "            p_atten = torch.zeros(attn_weights.shape[0], len(input2index)).to(device)\n",
    "            p_atten.scatter_add_(1, input_tensor, attn_weights)\n",
    "            p_w = p_gen * p_vocab + (1 - p_gen) * p_atten[:, 1:char_vocab_size]\n",
    "            decoder_input = Embedder(p_w.argmax(dim=1) + 1)\n",
    "            outputs.append(p_w)\n",
    "            if attn_debug:\n",
    "                attn_weights_sequence.append(attn_weights)\n",
    "                p_gen_seq.append(p_gen)\n",
    "\n",
    "        if attn_debug:\n",
    "            attn_weights_sequence = torch.stack(attn_weights_sequence, dim=1)\n",
    "            attn_weights_all.append(attn_weights_sequence)\n",
    "            p_gen_all.append(torch.cat(p_gen_seq, dim=1))\n",
    "        output_indices.append(torch.stack(outputs).argmax(dim=2))\n",
    "        inflected_forms_true += inflected_forms\n",
    "\n",
    "    output_indices = torch.cat(output_indices, dim=1).transpose(0, 1).cpu().numpy()\n",
    "    for indices in output_indices:\n",
    "        inflected_predicted.append(''.join([index2input[index + 1] for index in indices]).split(STOP_CHAR)[0])\n",
    "\n",
    "    if attn_debug:\n",
    "        max_src_len = max([x.shape[2] for x in attn_weights_all])\n",
    "        for i in range(len(attn_weights_all)):\n",
    "            attn_weights = attn_weights_all[i]\n",
    "            batch_size = attn_weights.shape[0]\n",
    "            src_len = attn_weights.shape[2]\n",
    "            attn_weights_all[i] = torch.zeros(batch_size, max_pred_len, max_src_len)\n",
    "            attn_weights_all[i][:,:,:src_len] = attn_weights\n",
    "        attn_weights_all = torch.cat(attn_weights_all, dim=0)\n",
    "        p_gen_all = torch.cat(p_gen_all, dim=0)\n",
    "        return inflected_predicted, input_seq, attn_weights_all, p_gen_all\n",
    "    else:\n",
    "        return inflected_predicted, inflected_forms_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lemmas_train, tags_train, inflected_forms_train, epochs=1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in grouper(zip(lemmas_train, tags_train, inflected_forms_train), batch_size):\n",
    "            batch = list(filter(lambda x: x is not None, batch))\n",
    "            lemmas, tags, inflected_forms = zip(*batch)\n",
    "\n",
    "\n",
    "            lemmas_indices = words_to_indices(lemmas, input2index, start_char=True, stop_char=True)\n",
    "            tags_indices = tag_to_indices(tags, input2index)    \n",
    "            inflected_forms_indices = words_to_indices(inflected_forms, input2index)\n",
    "            input_indices = merge_lists(lemmas_indices, tags_indices)\n",
    "\n",
    "            # Sort by length of input sequence\n",
    "            input_indices, inflected_forms_indices = zip(*sorted(zip(input_indices, inflected_forms_indices), key=lambda x: len(x[0]), reverse=True))\n",
    "            input_indices = [torch.tensor(lst) for lst in input_indices]\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            input_tensor = pad_sequence(input_indices, padding_value=input2index[PAD_CHAR], batch_first=True).to(device)\n",
    "            embedding = Embedder(input_tensor)\n",
    "            lengths = [Tensor.shape[0] for Tensor in input_indices]\n",
    "            packed_input = pack_padded_sequence(embedding, lengths, batch_first=True)\n",
    "            encoded_packed_seq, (hidden, cell) = Encoder(packed_input)\n",
    "            encoded_input = pad_packed_sequence(encoded_packed_seq, batch_first=True)[0]\n",
    "\n",
    "            input_mask = input_tensor == 0\n",
    "            # input_mask = torch.where(input_mask > 0, torch.zeros_like(input_mask), torch.ones_like(input_mask) * float('inf')) \n",
    "\n",
    "            # Decode\n",
    "            hidden_state = hidden[0,:,:] + hidden[1,:,:]\n",
    "            hidden_state = hidden_state.unsqueeze(0)\n",
    "            cell_state = torch.zeros(1, len(lengths), hidden_size).to(device)\n",
    "\n",
    "            target = pad_lists([lst + [input2index[STOP_CHAR]] for lst in inflected_forms_indices], input2index[PAD_CHAR]).to(device)    \n",
    "            target = target - 1\n",
    "\n",
    "            decoder_input = pad_lists(inflected_forms_indices, input2index[PAD_CHAR]).to(device)\n",
    "            decoder_input = torch.cat([torch.tensor([input2index[START_CHAR]] * len(lengths)).unsqueeze(1).to(device), decoder_input], dim=1)\n",
    "            decoder_input = Embedder(decoder_input)\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            max_length = target.shape[1]\n",
    "            for seq in range(0, max_length):\n",
    "                attn_weights = attention(encoded_input, hidden_state, input_mask)\n",
    "                context = torch.bmm(attn_weights.unsqueeze(1), encoded_input).squeeze()\n",
    "\n",
    "                decoder_input_concat = torch.cat([context.unsqueeze(1), decoder_input[:,seq,:].unsqueeze(1)], dim=2)\n",
    "\n",
    "                output, (hidden_state, cell_state) = Decoder(decoder_input_concat, (hidden_state, cell_state))\n",
    "                p_vocab = F.relu(linear_vocab(torch.cat([hidden_state, context.unsqueeze(0)], dim=2)))\n",
    "                p_vocab = F.softmax(p_vocab.squeeze(), dim=1)\n",
    "\n",
    "                p_gen = generation_prob(context, hidden_state, decoder_input[:,seq,:])\n",
    "                p_atten = torch.zeros(attn_weights.shape[0], len(input2index)).to(device)\n",
    "                p_atten.scatter_add_(1, input_tensor, attn_weights)\n",
    "                p_w = p_gen * p_vocab + (1 - p_gen) * p_atten[:, 1:char_vocab_size]\n",
    "\n",
    "                p_w = torch.log(p_w)\n",
    "                loss += criterion(p_w, target[:,seq])\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "        print(\"Epoch: {}/{}\\tTime: {:.2f}s\\tLoss: {:.4f}\\tAccuracy: {:.4f}\\tDistance: {:.4f} \".format(epoch+1, epochs, time.time() - start_time, epoch_loss / len(lemmas_train), *evaluate(*test(lemmas_val, tags_val, inflected_forms_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.Adagrad(params, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\tTime: 10.53s\tLoss: 7.3870\tAccuracy: 0.0205\tDistance: 5.1515 \n",
      "Epoch: 2/50\tTime: 22.55s\tLoss: 3.9669\tAccuracy: 0.1060\tDistance: 4.3375 \n",
      "Epoch: 3/50\tTime: 35.04s\tLoss: 2.8955\tAccuracy: 0.1605\tDistance: 3.4315 \n",
      "Epoch: 4/50\tTime: 47.03s\tLoss: 2.2719\tAccuracy: 0.3050\tDistance: 2.8590 \n",
      "Epoch: 5/50\tTime: 59.19s\tLoss: 2.0150\tAccuracy: 0.3120\tDistance: 2.6380 \n",
      "Epoch: 6/50\tTime: 71.13s\tLoss: 1.6915\tAccuracy: 0.3940\tDistance: 2.0190 \n",
      "Epoch: 7/50\tTime: 82.87s\tLoss: 1.4067\tAccuracy: 0.4450\tDistance: 1.7955 \n",
      "Epoch: 8/50\tTime: 95.65s\tLoss: 1.1772\tAccuracy: 0.4975\tDistance: 1.6325 \n",
      "Epoch: 9/50\tTime: 108.17s\tLoss: 1.0138\tAccuracy: 0.5700\tDistance: 1.3630 \n",
      "Epoch: 10/50\tTime: 120.68s\tLoss: 0.8866\tAccuracy: 0.5970\tDistance: 1.1500 \n",
      "Epoch: 11/50\tTime: 132.85s\tLoss: 0.8830\tAccuracy: 0.6065\tDistance: 1.1870 \n",
      "Epoch: 12/50\tTime: 145.02s\tLoss: 0.7841\tAccuracy: 0.6100\tDistance: 1.1420 \n",
      "Epoch: 13/50\tTime: 157.71s\tLoss: 0.8562\tAccuracy: 0.6080\tDistance: 1.2995 \n",
      "Epoch: 14/50\tTime: 170.80s\tLoss: 0.7491\tAccuracy: 0.6195\tDistance: 1.1450 \n",
      "Epoch: 15/50\tTime: 183.35s\tLoss: 0.8522\tAccuracy: 0.6355\tDistance: 1.0295 \n",
      "Epoch: 16/50\tTime: 194.68s\tLoss: 0.7047\tAccuracy: 0.6610\tDistance: 1.0145 \n",
      "Epoch: 17/50\tTime: 209.39s\tLoss: 0.6123\tAccuracy: 0.6930\tDistance: 0.8570 \n",
      "Epoch: 18/50\tTime: 221.47s\tLoss: 0.5565\tAccuracy: 0.7060\tDistance: 0.8270 \n",
      "Epoch: 19/50\tTime: 233.32s\tLoss: 0.4983\tAccuracy: 0.7365\tDistance: 0.7320 \n",
      "Epoch: 20/50\tTime: 246.30s\tLoss: 0.4706\tAccuracy: 0.7330\tDistance: 0.7550 \n",
      "Epoch: 21/50\tTime: 258.05s\tLoss: 0.4900\tAccuracy: 0.7305\tDistance: 0.8195 \n",
      "Epoch: 22/50\tTime: 270.68s\tLoss: 0.5303\tAccuracy: 0.6910\tDistance: 0.8780 \n",
      "Epoch: 23/50\tTime: 282.30s\tLoss: 0.5593\tAccuracy: 0.6970\tDistance: 0.8600 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a03c02b12fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prun'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train(lemmas_train, tags_train, inflected_forms_train, epochs=50)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2095\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2096\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-56>\u001b[0m in \u001b[0;36mprun\u001b[0;34m(self, parameter_s, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mprun\u001b[0;34m(self, parameter_s, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0marg_str\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0marg_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_splitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_with_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_with_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36m_run_with_profiler\u001b[0;34m(self, code, opts, namespace)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mprof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mprof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0msys_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/cProfile.py\u001b[0m in \u001b[0;36mrunctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-fc29fb613a5d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(lemmas_train, tags_train, inflected_forms_train, epochs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {}/{}\\tTime: {:.2f}s\\tLoss: {:.4f}\\tAccuracy: {:.4f}\\tDistance: {:.4f} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minflected_forms_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "%prun train(lemmas_train, tags_train, inflected_forms_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.Adagrad(params, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(lemmas_train, tags_train, inflected_forms_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.Adagrad(params, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(lemmas_train, tags_train, inflected_forms_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy:\", evaluate(*test(lemmas_train, tags_train, inflected_forms_train)), \"Validation accuracy: \", evaluate(*test(lemmas_val, tags_val, inflected_forms_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred, input_seq, attn_weights, p_gens = test(lemmas_val[:100], tags_val[:100], inflected_forms_val[:100], batch_size=32, attn_debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9714,  1.0000,  1.0000,  1.0000,  0.9998,  1.0000,  1.0000,\n",
       "         0.9999,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "         1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "         1.0000,  1.0000,  1.0000,  1.0000], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_gens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions, font=None):\n",
    "    # https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "        \n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    font = FontProperties(fname=font, size=24)\n",
    "    ax.set_xticklabels([''] + input_sentence, rotation=90, fontproperties=font)\n",
    "    ax.set_yticklabels([''] + output_words, fontproperties=font)\n",
    "    ax.tick_params(axis='both', which='major', pad=15)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: axis: ⏵, t, o, u, r, n, o, y, e, r, ⏹, V, 1, PL, SBJV, PST, IPFV\n",
      "Y: axis: t, o, u, r, n, o, y, a, s, s, i, o, n, s tournoyassions\n",
      "Correct:  tournoyassions\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f03e3edfe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "print('X: axis:', ', '.join(list(input_seq[i])))\n",
    "print('Y: axis:', ', '.join(list(pred[i])), pred[i])\n",
    "print(\"Correct: \", inflected_forms_val[lemmas_val.index(''.join(input_seq[i])[1:].split(STOP_CHAR)[0])])\n",
    "showAttention(input_seq[i], list(pred[i]), attn_weights[i, :len(pred[i])].cpu().detach().numpy(), 'Nirmala.ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(zip(*test(lemmas_val, tags_val, inflected_forms_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_dev, tags_dev, inflected_forms_dev = load_data('./conll2018/task1/all/{}-dev'.format(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.741, 0.746)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(*test(lemmas_dev, tags_dev, inflected_forms_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hindi/high - (0.765, 0.782), Initial LR: 0.1, very different results on different initialisations  \n",
    "Middle-French/high - (0.873, 0.365) - Probability of generation always one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prediction, truth in zip(*test(lemmas_dev, tags_dev, inflected_forms_dev)):\n",
    "    if prediction != truth:\n",
    "        print(\"Prediction: {}\\tTruth: {}\".format(prediction, truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
